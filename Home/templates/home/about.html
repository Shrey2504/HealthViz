<!DOCTYPE html>
<html lang="en">
  {%load static%}
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, shrink-to-fit=no"
    />
    <title>Services - Brand</title>
    <link
      rel="stylesheet"
      href="{% static 'home/assets/bootstrap/css/bootstrap.min.css' %}"
    />
    <link rel="stylesheet" href="{% static 'home/assets/css/Aldrich.css' %}" />
    <link rel="stylesheet" href="{% static 'home/assets/css/Inter.css' %}" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css"
    />
    <link
      rel="stylesheet"
      href="https://unpkg.com/@bootstrapstudio/bootstrap-better-nav/dist/bootstrap-better-nav.min.css"
    />
    <link
      rel="stylesheet"
      href="{% static 'home/assets/css/Login-Form-Basic-icons.css' %}"
    />
    <link
      rel="stylesheet"
      href="{% static 'home/assets/css/Signup-page-with-overlay.css' %}"
    />
    <link
      rel="stylesheet"
      href="{% static 'home/assets/css/TD-BS4-Simple-Contact-Form-styles.css' %}"
    />
    <link
      rel="stylesheet"
      href="{% static 'home/assets/css/TD-BS4-Simple-Contact-Form.css' %}"
    />
  </head>

  <body
    style="background: linear-gradient(180deg, #150f28 0%, rgb(83, 54, 92) 58%)"
  >
    <!-- Start: Navbar Centered Links -->
    {%include 'home/nav.html'%}
    <!-- End: Navbar Centered Links -->
    <header class="bounce animated" style="padding-top: 22px">
      <h1 class="text-center" style="font-weight: bold; font-size: 55px">
        About
      </h1>
    </header>
    <section class="pulse animated py-5">
      <section>
        <div
          class="row row-cols-1 row-cols-md-2 mx-auto"
          style="max-width: 900px"
        >
          <div class="col mb-5">
            <img
              class="rounded img-fluid shadow"
              src="https://cdn-images-1.medium.com/max/1600/0*Z4IPWQR2JdGhcJsq."
            />
          </div>
          <div
            class="col d-md-flex align-items-md-end align-items-lg-center mb-5"
          >
            <div>
              <p
                class="mb-4"
                style="
                  font-family: Inter, sans-serif;
                  text-align: justify;
                  font-size: 16px;
                  font-weight: bold;
                "
              >
                Welcome to our Medical Models Web Application, where we combine
                the power of Convolutional Neural Networks (CNNs), Vision
                Transformers (ViTs), and traditional Machine Learning algorithms
                like Random Forest and XGBoost to provide cutting-edge solutions
                for medical data analysis.
              </p>
            </div>
          </div>
        </div>
        <div
          class="row row-cols-1 row-cols-md-2 mx-auto"
          style="max-width: 900px"
        >
          <div class="col order-md-last mb-5">
            <img
              class="rounded img-fluid shadow"
              src="https://pic3.zhimg.com/v2-7b2a74a772ec21bd37082dbfc7f1009a_b.jpg"
              style="height: 352.5px; width: 405.8px"
            />
          </div>
          <div
            class="col d-md-flex align-items-md-end align-items-lg-center mb-5"
          >
            <div>
              <p
                class="mb-4"
                style="font-size: 20px; text-align: justify; font-weight: bold"
              ></p>
              <h5
                class="fw-bold"
                style="
                  font-size: 26px;
                  font-family: Aldrich, sans-serif;
                  color: rgb(213, 171, 255);
                "
              >
                Vision Transformers (ViT)
              </h5>
              <p
                class="mb-4"
                style="text-align: justify; font-size: 14px; font-weight: bold"
              >
                This was introduced by researchers at Google in a groundbreaking
                paper titled -&nbsp;"An Image is Worth 16x16 Words: Transformers
                for Image Recognition at Scale." Vision Transformer (ViT) has
                gained a lot of prominence in the field of computer vision.
                Unlike traditional Convolutional Neural Networks (CNNs), ViTs
                rely on a transformer-based architecture originally designed for
                natural language processing tasks.
              </p>
            </div>
          </div>
        </div>
        <div
          class="row row-cols-1 row-cols-md-2 mx-auto"
          style="max-width: 900px"
        >
          <div class="col mb-5">
            <img
              class="rounded img-fluid shadow"
              src="https://www.xenonstack.com/hubfs/data-preparation-xenonstack.jpg"
              style="height: 157.387px; width: 451px"
            />
          </div>
          <div
            class="col d-md-flex align-items-md-end align-items-lg-center mb-5"
          >
            <div>
              <p
                class="mb-4"
                style="font-size: 20px; text-align: justify; font-weight: bold"
              ></p>
              <h5
                class="fw-bold"
                style="
                  font-size: 22px;
                  text-align: center;
                  color: var(--bs-yellow);
                "
              >
                Here are some of the essential steps involved.
              </h5>
            </div>
          </div>
          <div
            class="col d-md-flex align-items-md-end align-items-lg-center mb-5"
          >
            <div>
              <p
                class="mb-4"
                style="font-size: 20px; text-align: justify; font-weight: bold"
              ></p>
              <h5
                class="fw-bold"
                style="
                  font-size: 26px;
                  font-family: Aldrich, sans-serif;
                  color: #9ec1ff;
                "
              >
                Mechanisms of ViT:
              </h5>
              <p
                class="mb-4"
                style="
                  font-size: 18px;
                  text-align: justify;
                  font-weight: bold;
                  color: #9ec1ff;
                  font-family: Aldrich, sans-serif;
                "
              >
                Patch Embedding:
              </p>
              <p
                style="text-align: justify; font-size: 14px; font-weight: bold"
              >
                <span style="color: var(--bs-body-color)"
                  >In this step, the input image is divided into non-overlapping
                  patches. These patches are typically smaller regions of the
                  image, such as 16x16 pixel squares.</span
                >Each patch is linearly embedded into a high-dimensional vector
                representation.&nbsp;
              </p>
              <p
                style="
                  text-align: justify;
                  font-size: 18px;
                  font-weight: bold;
                  color: #9ec1ff;
                  font-family: Aldrich, sans-serif;
                "
              >
                Positional Encoding:
              </p>
              <p
                style="text-align: justify; font-size: 14px; font-weight: bold"
              >
                <span style="color: var(--bs-body-color)"
                  >Since ViTs do not inherently possess positional information,
                  positional encoding is added to the patch embeddings.</span
                >Positional encoding ensures that the model can capture spatial
                relationships between patches and learn from the image's overall
                structure.
              </p>
            </div>
          </div>
          <div class="col mb-5">
            <p
              class="mb-4"
              style="font-size: 20px; text-align: justify; font-weight: bold"
            ></p>
            <img
              class="rounded img-fluid shadow"
              src="https://miro.medium.com/max/700/1*_c8SqxPMY_dsApyvDJ8HtA.gif"
              style="height: 359.875px"
            />
          </div>
          <div class="col mb-5">
            <img
              class="rounded img-fluid shadow"
              src="http://jalammar.github.io/images/t/transformer_decoding_1.gif"
              style="height: 289.188px; width: 432px"
              width="426"
              height="285"
            />
          </div>
          <div
            class="col d-md-flex align-items-md-end align-items-lg-center mb-5"
          >
            <div>
              <p
                class="mb-4"
                style="
                  font-size: 20px;
                  text-align: justify;
                  font-weight: bold;
                  color: #9ec1ff;
                  font-family: Aldrich, sans-serif;
                "
              >
                Transformer Architecture:
              </p>
              <p
                style="text-align: justify; font-size: 14px; font-weight: bold"
              >
                It takes the patch embeddings with positional encodings as
                input. Self-attention mechanisms within the transformer allow
                the model to learn complex relationships between patches and
                their relative importance in the context of the entire image.
              </p>
              <p
                style="text-align: justify; font-size: 14px; font-weight: bold"
              >
                The model consists of multiple transformer layers (e.g., encoder
                layers), enabling it to capture hierarchical features at
                different scales. After processing through these layers, the
                final output is passed to a classification head, which makes
                predictions based on the information learned by the ViT.
              </p>
            </div>
          </div>
          <div
            class="col d-md-flex align-items-md-end align-items-lg-center mb-5"
          >
            <div>
              <p
                class="mb-4"
                style="
                  font-size: 26px;
                  font-family: Aldrich, sans-serif;
                  font-weight: bold;
                  color: rgb(186, 255, 143);
                "
              >
                CNN vs ViT:
              </p>
              <p
                style="text-align: justify; font-size: 14px; font-weight: bold"
              >
                In medical imaging, ViTs shine in tasks such as identifying
                complex anatomical structures or detecting abnormalities spread
                across the entire image. For example, in identifying tumors in
                radiology images, ViTs can consider the context of the entire
                image, including the relative position of the tumor within the
                organ.
              </p>
              <p
                style="text-align: justify; font-size: 14px; font-weight: bold"
              >
                ViTs can easily scale to handle high-resolution images without
                major architectural changes. The self-attention mechanism allows
                them to adapt to different image sizes effectively.
              </p>
            </div>
          </div>
          <div class="col mb-5">
            <img
              class="rounded img-fluid shadow"
              src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OOXskSX5oqXcwyZt.png"
              style="padding-bottom: 43px"
            /><img
              class="rounded img-fluid shadow"
              src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Kz2rPigm0BbTLvIQ.png"
            />
          </div>
        </div>
      </section>
    </section>
    <!-- Start: Footer Dark -->
    <footer class="text-center bg-dark">
      <div class="container text-white py-4 py-lg-5">
        <ul class="list-inline">
          <li class="list-inline-item me-4">
            <a class="link-light" href="#">Machine Learning</a>
          </li>
          <li class="list-inline-item me-4">
            <a class="link-light" href="#">Deep Learning</a>
          </li>
          <li class="list-inline-item">
            <a class="link-light" href="#">Artificial Intelligence</a>
          </li>
        </ul>
        <p class="text-white mb-0">Copyright © 2023 DIAGNO-VISION</p>
      </div>
    </footer>
    <!-- End: Footer Dark -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    <script src="{% static 'home/assets/js/bs-init.js' %}"></script>
    <script src="{% static 'home/assets/js/bold-and-dark.js' %}"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.2/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
    <script src="https://unpkg.com/@bootstrapstudio/bootstrap-better-nav/dist/bootstrap-better-nav.min.js"></script>
  </body>
</html>
